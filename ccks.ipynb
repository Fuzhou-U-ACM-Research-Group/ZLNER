{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert预训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bert预训练\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "args = {\n",
    "    'num_epochs': 50,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    # 'pretrained_file_name': './save_pretrained/ccks_pre_1/Bert_5915/pytorch_model.bin',\n",
    "    'max_seq_length': 512,\n",
    "    'max_scan_num': 1000000,\n",
    "    'train_file': './data/ccks/train.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'ptloader_v2',\n",
    "    \"word_embedding_file\": \"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\": \"./data/tencent/tencent_vocab.txt\",\n",
    "    \"word_vocab_file_with_tag\": \"./data/tencent/tencent_vocab_with_tag.json\",\n",
    "    \"default_tag\": \"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 32,\n",
    "    'pass_none_rule': True,\n",
    "    'skip_single_matched_word': True,\n",
    "    'do_shuffle': True,\n",
    "    'task_name': 'ccks_pre_1',\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    \"tag_rules\": {\n",
    "        \"O\": \"非实体\",\n",
    "        # \"KEYWORD\": \"关键词\",\n",
    "        \"DIS\": \"疾病或诊断\",\n",
    "        \"ANA\": \"解剖部位\",\n",
    "        \"LAB\": \"实验室检验\",\n",
    "        \"MED\": \"药物\",\n",
    "        \"OPE\": \"手术\",\n",
    "        \"IMA\": \"影像检查\",\n",
    "        # \"CHECK\":\"检查\",\n",
    "    }\n",
    "}\n",
    "\n",
    "from CC.pre_trained import NERPreTrainer\n",
    "pre_trainer = NERPreTrainer(**args)\n",
    "\n",
    "for i in pre_trainer(lr=1e-5):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_250.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_250_bert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_250.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_250_bert_lstm_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_lstm_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_lstm_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_lstm_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_bert_lstm_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_250.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_250_LEBert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBERT + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_250.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_250_LEBert_bilstm_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_bilstm_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_bilstm_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_bilstm_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_LEBert_bilstm_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBERT - BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_250.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_250_ZL_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_250.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_250_ZL_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_250_ZL_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_500_2.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_500_bert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_500_2.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_500_bert_lstm_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_lstm_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_lstm_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_lstm_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_bert_lstm_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_500_2.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_500_LEBert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBERT + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_500_2.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_500_LEBert_bilstm_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_bilstm_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_bilstm_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_bilstm_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_LEBert_bilstm_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBERT - BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_500_2.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_500_ZL_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_500_2.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_500_ZL_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_500_ZL_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 750"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_750.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_750_bert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_750.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_750_bert_lstm_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_lstm_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_lstm_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_lstm_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_bert_lstm_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_750.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_750_LEBert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBERT + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_750.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_750_LEBert_bilstm_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_bilstm_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_bilstm_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_bilstm_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_LEBert_bilstm_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBERT - BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_750.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_750_ZL_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_750.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_750_ZL_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_750_ZL_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_1000.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_1000_bert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_1000.txt',\n",
    "    'eval_file': './data/ccks/test.txt',\n",
    "    'test_file': './data/ccks/test.txt',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'cn_loader',\n",
    "    'output_eval':True,\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'Bert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_1000_bert_lstm_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_lstm_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_lstm_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_lstm_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_bert_lstm_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_1000.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_1000_LEBert_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LEBERT + BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_1000.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'LEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_1000_LEBert_bilstm_1',\n",
    "\n",
    "}\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_bilstm_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_bilstm_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_bilstm_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_LEBert_bilstm_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBERT - BiLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_1000.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'crf',\n",
    "    'task_name': 'ccks_1000_ZL_crf_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_crf_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_crf_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_crf_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_crf_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZLEBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'\n",
    "from CC.trainer import NERTrainer\n",
    "\n",
    "args = {\n",
    "    'num_epochs': 30,\n",
    "    'num_gpus': [0],\n",
    "    'bert_config_file_name': './model/chinese_wwm_ext/bert_config.json',\n",
    "    'pretrained_file_name': './model/chinese_wwm_ext/pytorch_model.bin',\n",
    "    'hidden_dim': 300,\n",
    "    'max_seq_length': 128,\n",
    "    'train_file': './data/ccks/train_1000.json',\n",
    "    'eval_file': './data/ccks/test.json',\n",
    "    'test_file': './data/ccks/test.json',\n",
    "    'bert_vocab_file': './model/chinese_wwm_ext/vocab.txt',\n",
    "    'tag_file': './data/ccks/labels.txt',\n",
    "    'loader_name': 'le_loader_zl',\n",
    "    'output_eval':True,\n",
    "    \"word_embedding_file\":\"./data/tencent/word_embedding.txt\",\n",
    "    \"word_vocab_file\":\"./data/tencent/tencent_vocab.txt\",\n",
    "    \"inter_knowledge_file\":\"./data/tencent/THUOCL_FN_medical.txt\",\n",
    "    \"default_tag\":\"O\",\n",
    "    'batch_size': 8,\n",
    "    'eval_batch_size': 64,\n",
    "    'do_shuffle': True,\n",
    "    \"use_gpu\": True,\n",
    "    \"debug\": True,\n",
    "    'model_name': 'ZLEBert',\n",
    "    'classify':'lstm_crf',\n",
    "    'task_name': 'ccks_1000_ZL_1',\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_2\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_3\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_4\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n",
    "\n",
    "\n",
    "args[\"task_name\"] = \"ccks_1000_ZL_5\"\n",
    "\n",
    "trainer = NERTrainer(**args)\n",
    "\n",
    "for i in trainer(lr2=1e-2):\n",
    "    a = i\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c9392d1f0914889243d058bb73f0d89e61311fd6d751bbc8fa50e38d7d4ff811"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 64-bit ('NER': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
